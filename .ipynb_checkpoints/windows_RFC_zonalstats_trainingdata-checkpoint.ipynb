{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5d7071ad",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'Iterable' from 'collections' (C:\\Users\\ariane\\anaconda3\\envs\\nansenproject2\\lib\\collections\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Input \u001b[1;32mIn [10]\u001b[0m, in \u001b[0;36m<cell line: 12>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mrasterio\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mrasterstats\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mensemble\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RandomForestClassifier\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_test_split, cross_val_score\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\nansenproject2\\lib\\site-packages\\rasterstats\\__init__.py:2\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# -*- coding: utf-8 -*-\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmain\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m gen_zonal_stats, raster_stats, zonal_stats\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpoint\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m gen_point_query, point_query\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mrasterstats\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m cli\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\nansenproject2\\lib\\site-packages\\rasterstats\\main.py:11\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msystem_info\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msysinfo\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mwarnings\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m read_features, Raster\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (rasterize_geom, get_percentile, check_stats,\n\u001b[0;32m     13\u001b[0m                     remap_categories, key_assoc_val, boxify_points)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mraster_stats\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\nansenproject2\\lib\\site-packages\\rasterstats\\io.py:24\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     22\u001b[0m     JSONDecodeError \u001b[38;5;241m=\u001b[39m \u001b[38;5;167;01mValueError\u001b[39;00m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mshapely\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m wkt, wkb\n\u001b[1;32m---> 24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcollections\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Iterable, Mapping\n\u001b[0;32m     27\u001b[0m geom_types \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPoint\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLineString\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPolygon\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     28\u001b[0m               \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMultiPoint\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMultiLineString\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMultiPolygon\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m     30\u001b[0m PY3 \u001b[38;5;241m=\u001b[39m sys\u001b[38;5;241m.\u001b[39mversion_info[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3\u001b[39m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'Iterable' from 'collections' (C:\\Users\\ariane\\anaconda3\\envs\\nansenproject2\\lib\\collections\\__init__.py)"
     ]
    }
   ],
   "source": [
    "#### New attempt to classify, according to: https://gis.stackexchange.com/questions/373720/performing-supervised-classification-on-sentinel-images\n",
    "\n",
    "\n",
    "from nansat import Nansat\n",
    "from osgeo import gdal\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import rasterio\n",
    "import scipy\n",
    "import rasterstats\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, accuracy_score\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import preprocessing\n",
    "\n",
    "import matplotlib as mpl\n",
    "mpl.use('Qt5Agg')\n",
    "import matplotlib.pyplot as plt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cd7bb5c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "s2_path = r'C:/Users/ariane/shared/NERSC/classification/subsets/'\n",
    "rpoints = 'C:/Users/ariane/shared/NERSC/classification/rasterpoints.shp'\n",
    "path = 'C:/Users/ariane/shared/NERSC/classification/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7ba6b875",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subset_S2A_20210419_resampled.tif\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'zonal_stats' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [7]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(file)\n\u001b[0;32m      9\u001b[0m stats \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;66;03m#Since we are using point files there's no reason for 'mean', 'median' 'std' etc...\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m df2 \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(\u001b[43mzonal_stats\u001b[49m(vectors\u001b[38;5;241m=\u001b[39mdf[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgeometry\u001b[39m\u001b[38;5;124m'\u001b[39m], raster\u001b[38;5;241m=\u001b[39mf, stats\u001b[38;5;241m=\u001b[39mstats))\n\u001b[0;32m     11\u001b[0m df2\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(stat, file\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;28;01mfor\u001b[39;00m stat \u001b[38;5;129;01min\u001b[39;00m stats]\n\u001b[0;32m     12\u001b[0m df \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mjoin(df2)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'zonal_stats' is not defined"
     ]
    }
   ],
   "source": [
    "df = gpd.read_file(rpoints) #Create geodataframe from the points\n",
    "\n",
    "#Calulate statistic(s) for each point\n",
    "for root, folders, files in os.walk(s2_path):\n",
    "    for file in files:\n",
    "        f = os.path.join(root, file)\n",
    "        if os.path.isfile(f) and f.endswith('.tif'): #I use blue, green, red and infrared bands\n",
    "            print(file)\n",
    "            stats = ['max'] #Since we are using point files there's no reason for 'mean', 'median' 'std' etc...\n",
    "            df2 = pd.DataFrame(zonal_stats(vectors=df['geometry'], raster=f, stats=stats))\n",
    "            df2.columns=['{0}_{1}'.format(stat, file.split('.')[0]) for stat in stats]\n",
    "            df = df.join(df2)       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "471d9a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split data into train and test (https://stackoverflow.com/questions/24147278/how-do-i-create-test-and-train-samples-from-one-dataframe-with-pandas)\n",
    "msk = np.random.rand(len(df)) < 0.8\n",
    "train = df[msk]\n",
    "test = df[~msk]\n",
    "\n",
    "#Train the model\n",
    "predictor_cols = ['max_B02', 'max_B03', 'max_B04', 'max_B08']\n",
    "X = train[predictor_cols].values.tolist() #List of lists: [64.0, 33.0, 41.0, 43.0] #X are the stats/predictor data\n",
    "y = train['classid'].tolist() #y[:5]: [1, 1, 1, 1, 1] #y are the classes\n",
    "\n",
    "clf = make_pipeline(StandardScaler(),\n",
    "                    RandomForestClassifier(n_estimators = 100, n_jobs = -1, random_state=50)) \n",
    "clf.fit(X, y)\n",
    "\n",
    "#Test\n",
    "Xtest = test[predictor_cols]\n",
    "ytest = test['classid']\n",
    "p = clf.predict(Xtest)\n",
    "clf.score(Xtest,ytest)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nansenproject2",
   "language": "python",
   "name": "nansenproject2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
